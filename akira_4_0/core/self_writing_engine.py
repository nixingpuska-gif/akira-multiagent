"""
AKIRA 4.0 Self-Writing Engine
System that generates, tests, and improves its own code autonomously.
"""

import json
import subprocess
import tempfile
import os
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime
import logging
import ast
import re

logger = logging.getLogger(__name__)

@dataclass
class CodeGenerationRequest:
    module_name: str
    description: str
    requirements: List[str]
    test_cases: List[Dict]
    priority: str = "normal"  # low, normal, high, critical

@dataclass
class GeneratedCode:
    module_name: str
    code: str
    tests: str
    timestamp: str
    generation_attempt: int
    validation_status: str = "pending"  # pending, passed, failed

class SelfWritingEngine:
    """
    AKIRA's self-writing engine that generates, tests, and validates code.
    """
    
    def __init__(self):
        self.generated_modules: Dict[str, GeneratedCode] = {}
        self.generation_history: List[GeneratedCode] = []
        self.max_generation_attempts = 3
        self.code_quality_threshold = 0.85
        
    async def generate_module(self, request: CodeGenerationRequest) -> Tuple[bool, str]:
        """
        Generate a new module based on requirements.
        Returns (success, module_path_or_error_message)
        """
        logger.info(f"Starting code generation for module: {request.module_name}")
        
        for attempt in range(1, self.max_generation_attempts + 1):
            logger.info(f"Generation attempt {attempt}/{self.max_generation_attempts}")
            
            # Step 1: Generate code
            generated_code = await self._generate_code(request, attempt)
            if not generated_code:
                logger.error(f"Failed to generate code on attempt {attempt}")
                continue
            
            # Step 2: Generate tests
            generated_tests = await self._generate_tests(request, generated_code)
            if not generated_tests:
                logger.error(f"Failed to generate tests on attempt {attempt}")
                continue
            
            # Step 3: Validate syntax
            if not self._validate_syntax(generated_code):
                logger.error(f"Generated code has syntax errors on attempt {attempt}")
                continue
            
            # Step 4: Run tests
            test_results = await self._run_tests(generated_code, generated_tests)
            
            # Step 5: Validate results
            if test_results["passed"] and test_results["quality_score"] >= self.code_quality_threshold:
                logger.info(f"✅ Module generation SUCCESSFUL on attempt {attempt}")
                return await self._save_module(request.module_name, generated_code, generated_tests)
            else:
                logger.warning(f"Tests failed or quality too low on attempt {attempt}")
                logger.warning(f"Test results: {test_results}")
                continue
        
        logger.error(f"❌ Failed to generate module after {self.max_generation_attempts} attempts")
        return False, f"Failed to generate {request.module_name} after {self.max_generation_attempts} attempts"
    
    async def _generate_code(self, request: CodeGenerationRequest, attempt: int) -> Optional[str]:
        """
        Generate Python code based on requirements.
        Uses LLM to generate code.
        """
        prompt = f"""
You are AKIRA 4.0, an expert Python engineer. Generate production-ready Python code for:

Module: {request.module_name}
Description: {request.description}

Requirements:
{chr(10).join(f"- {req}" for req in request.requirements)}

Constraints:
- Code must be production-ready
- Include proper error handling
- Add comprehensive docstrings
- Follow PEP 8 standards
- Attempt number: {attempt}

Generate ONLY the Python code, no explanations. Start with imports, end with the last function/class.
"""
        
        try:
            # In production, this would call the LLM
            # For now, return a template
            code = f'''"""
{request.module_name} - Auto-generated by AKIRA 4.0
Generated: {datetime.now().isoformat()}
Attempt: {attempt}
"""

import logging
from typing import Dict, List, Optional

logger = logging.getLogger(__name__)

class {self._to_class_name(request.module_name)}:
    """Auto-generated module for {request.description}"""
    
    def __init__(self):
        logger.info(f"Initializing {request.module_name}")
        self.initialized = True
    
    def execute(self, *args, **kwargs) -> Dict:
        """Execute the module logic."""
        try:
            result = self._process(*args, **kwargs)
            return {{"status": "success", "result": result}}
        except Exception as e:
            logger.error(f"Error in {request.module_name}: {{str(e)}}")
            return {{"status": "error", "message": str(e)}}
    
    def _process(self, *args, **kwargs) -> any:
        """Internal processing logic."""
        return {{"processed": True, "args": args, "kwargs": kwargs}}
'''
            return code
            
        except Exception as e:
            logger.error(f"Error generating code: {str(e)}")
            return None
    
    async def _generate_tests(self, request: CodeGenerationRequest, code: str) -> Optional[str]:
        """
        Generate unit tests for the generated code.
        """
        class_name = self._to_class_name(request.module_name)
        
        tests = f'''"""
Tests for {request.module_name}
Auto-generated by AKIRA 4.0
"""

import pytest
from {request.module_name} import {class_name}

class Test{class_name}:
    """Test suite for {class_name}"""
    
    @pytest.fixture
    def instance(self):
        """Create an instance for testing."""
        return {class_name}()
    
    def test_initialization(self, instance):
        """Test that the module initializes correctly."""
        assert instance is not None
        assert instance.initialized == True
    
    def test_execute_success(self, instance):
        """Test successful execution."""
        result = instance.execute()
        assert result["status"] == "success"
        assert "result" in result
    
    def test_execute_with_args(self, instance):
        """Test execution with arguments."""
        result = instance.execute("arg1", "arg2", key="value")
        assert result["status"] == "success"
    
    @pytest.mark.parametrize("input_data", [
        {{"test": "data1"}},
        {{"test": "data2"}},
        {{"test": "data3"}}
    ])
    def test_execute_parametrized(self, instance, input_data):
        """Test with multiple inputs."""
        result = instance.execute(**input_data)
        assert result["status"] == "success"
'''
        
        return tests
    
    def _validate_syntax(self, code: str) -> bool:
        """
        Validate Python syntax of generated code.
        """
        try:
            ast.parse(code)
            logger.info("✅ Syntax validation passed")
            return True
        except SyntaxError as e:
            logger.error(f"❌ Syntax error: {str(e)}")
            return False
    
    async def _run_tests(self, code: str, tests: str) -> Dict:
        """
        Run the generated tests and return results.
        """
        try:
            with tempfile.TemporaryDirectory() as tmpdir:
                # Write code to file
                code_file = os.path.join(tmpdir, "generated_module.py")
                with open(code_file, "w") as f:
                    f.write(code)
                
                # Write tests to file
                test_file = os.path.join(tmpdir, "test_generated.py")
                with open(test_file, "w") as f:
                    f.write(tests)
                
                # Run pytest
                result = subprocess.run(
                    ["python", "-m", "pytest", test_file, "-v", "--tb=short"],
                    cwd=tmpdir,
                    capture_output=True,
                    text=True,
                    timeout=30
                )
                
                # Parse results
                passed = result.returncode == 0
                output = result.stdout + result.stderr
                
                # Calculate quality score
                quality_score = self._calculate_quality_score(code, passed, output)
                
                logger.info(f"Test results: {'PASSED' if passed else 'FAILED'}")
                logger.info(f"Quality score: {quality_score:.2f}")
                
                return {
                    "passed": passed,
                    "output": output,
                    "quality_score": quality_score
                }
                
        except subprocess.TimeoutExpired:
            logger.error("Test execution timed out")
            return {"passed": False, "output": "Timeout", "quality_score": 0.0}
        except Exception as e:
            logger.error(f"Error running tests: {str(e)}")
            return {"passed": False, "output": str(e), "quality_score": 0.0}
    
    def _calculate_quality_score(self, code: str, tests_passed: bool, test_output: str) -> float:
        """
        Calculate code quality score (0-1).
        """
        score = 0.0
        
        # Test results (50%)
        if tests_passed:
            score += 0.5
        
        # Code metrics (50%)
        # Check for docstrings
        if '"""' in code or "'''" in code:
            score += 0.1
        
        # Check for error handling
        if "try:" in code and "except" in code:
            score += 0.1
        
        # Check for logging
        if "logger" in code:
            score += 0.1
        
        # Check for type hints
        if "->" in code or ":" in code:
            score += 0.1
        
        # Check for reasonable length (not too short, not too long)
        lines = len(code.split('\n'))
        if 20 < lines < 500:
            score += 0.1
        
        return min(score, 1.0)
    
    async def _save_module(self, module_name: str, code: str, tests: str) -> Tuple[bool, str]:
        """
        Save the generated module to disk.
        """
        try:
            module_path = f"/home/ubuntu/akira_4_0/core/{module_name}.py"
            test_path = f"/home/ubuntu/akira_4_0/tests/test_{module_name}.py"
            
            # Create directories if needed
            os.makedirs(os.path.dirname(test_path), exist_ok=True)
            
            # Save code
            with open(module_path, "w") as f:
                f.write(code)
            
            # Save tests
            with open(test_path, "w") as f:
                f.write(tests)
            
            logger.info(f"✅ Module saved: {module_path}")
            logger.info(f"✅ Tests saved: {test_path}")
            
            # Store in history
            generated = GeneratedCode(
                module_name=module_name,
                code=code,
                tests=tests,
                timestamp=datetime.now().isoformat(),
                generation_attempt=1,
                validation_status="passed"
            )
            self.generated_modules[module_name] = generated
            self.generation_history.append(generated)
            
            return True, module_path
            
        except Exception as e:
            logger.error(f"Error saving module: {str(e)}")
            return False, str(e)
    
    def _to_class_name(self, module_name: str) -> str:
        """Convert module name to class name."""
        return ''.join(word.capitalize() for word in module_name.split('_'))
    
    def get_generation_report(self) -> Dict:
        """Get a report of all generated modules."""
        return {
            "total_generated": len(self.generated_modules),
            "modules": {
                name: {
                    "timestamp": gen.timestamp,
                    "validation_status": gen.validation_status,
                    "lines_of_code": len(gen.code.split('\n'))
                }
                for name, gen in self.generated_modules.items()
            },
            "history": [
                {
                    "module": gen.module_name,
                    "timestamp": gen.timestamp,
                    "status": gen.validation_status
                }
                for gen in self.generation_history[-10:]  # Last 10
            ]
        }

# Example usage
if __name__ == "__main__":
    import asyncio
    
    async def main():
        engine = SelfWritingEngine()
        
        request = CodeGenerationRequest(
            module_name="sample_module",
            description="A sample auto-generated module",
            requirements=[
                "Must have an execute method",
                "Must handle errors gracefully",
                "Must be testable"
            ],
            test_cases=[
                {"name": "test_init", "expected": "success"},
                {"name": "test_execute", "expected": "success"}
            ]
        )
        
        success, result = await engine.generate_module(request)
        print(f"Generation result: {success}")
        print(f"Details: {result}")
        
        if success:
            print("\nGeneration Report:")
            print(json.dumps(engine.get_generation_report(), indent=2))
    
    asyncio.run(main())
